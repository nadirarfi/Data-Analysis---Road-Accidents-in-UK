{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ff75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bb5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67376b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Check whether the specified path exists or not\n",
    "    Create a new directory if it does not exist \n",
    "    \"\"\"\n",
    "    isExist = os.path.exists(folder_path)\n",
    "    if not isExist:\n",
    "        os.makedirs(folder_path)\n",
    "path = \"./results/3_machine_learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f258dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \n",
    "    def __init__(self, name, clf, X_train, y_train, X_test, y_test):\n",
    "        self.clf = clf\n",
    "        self.name = name\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test        \n",
    "    \n",
    "    def run_classification(self):\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)\n",
    "        self.report = pd.DataFrame(classification_report(self.y_test, self.y_pred, output_dict=True))\n",
    "        self.cf_matrix = confusion_matrix(self.y_test, self.y_pred)\n",
    "        self.accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        print(self.cf_matrix)\n",
    "        print(self.report)\n",
    "        print(\"Accuracy: %.2f%%\" % (self.accuracy * 100.0))\n",
    "        self.results = {\n",
    "            \"classifier\": self.name,\n",
    "            \"average precision\": average_precision_score(self.y_test, self.y_pred),\n",
    "            \"precision\": precision_score(self.y_test, self.y_pred),\n",
    "            \"recall\": recall_score(self.y_test, self.y_pred),\n",
    "            \"accuracy\": accuracy_score(self.y_test, self.y_pred),            \n",
    "            \"f1 score\": f1_score(self.y_test, self.y_pred),\n",
    "            \"roc_auc\": roc_auc_score(self.y_test, self.y_pred)\n",
    "        }\n",
    "        self.save_results()\n",
    "    \n",
    "    def save_results(self):\n",
    "        folder_path = \"./results/3_machine_learning/{}/{}\".format(\"testing_models\", self.name)\n",
    "        create_folder(folder_path)\n",
    "        self.report = pd.DataFrame(classification_report(self.y_test, self.y_pred, output_dict=True))\n",
    "        self.report.to_csv(folder_path + \"classification_report.csv\")\n",
    "        #pd.DataFrame(self.y_pred).to_csv(folder_path + \"y_pred.csv\")\n",
    "        sns_plot = sns.heatmap(self.cf_matrix/np.sum(self.cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(\"./results/3_machine_learning/{}/{}/cf_matrix.png\".format(\"testing_models\", self.name))\n",
    "        fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1182733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Serious\n",
      "1        Serious\n",
      "2        Serious\n",
      "3        Serious\n",
      "4        Serious\n",
      "          ...   \n",
      "96057    Serious\n",
      "96058    Serious\n",
      "96059    Serious\n",
      "96060    Serious\n",
      "96061    Serious\n",
      "Name: accident_severity, Length: 96062, dtype: object\n",
      "Serious (24693, 14)\n",
      "Slight (45000, 14)\n",
      "[0 0 0 ... 0 0 0]\n",
      "(96062, 14)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"./results/0_data_cleaning/dataset.csv\")\n",
    "df =  pd.read_csv(\"./results/0_data_cleaning/train_dataset.csv\")\n",
    "\n",
    "X = df.drop('accident_severity',axis=1)\n",
    "y = df['accident_severity'].replace(['Fatal'], 'Serious')\n",
    "grp = df.groupby(\"accident_severity\")\n",
    "df_serious = grp.get_group(\"Serious\")\n",
    "df_slight = grp.get_group(\"Slight\")\n",
    "print(\"Serious\", df_serious.shape)\n",
    "print(\"Slight\", df_slight.shape)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "X_encoded = X.copy()\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == np.dtype('O'):\n",
    "        X_encoded[col] = LabelEncoder().fit_transform(X[col])\n",
    "    if X[col].dtype == np.dtype('int64') or X[col].dtype == np.dtype('float64'):\n",
    "        X_encoded[col] = StandardScaler().fit_transform(X[col].values.reshape(-1,1))\n",
    "\n",
    "        \n",
    "#Serious (24693, 14)\n",
    "#Slight (45000, 14)\n",
    "#df = pd.concat([df_serious.sample(20000), df_slight.sample(20000)])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ed65999",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=1, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c791cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(bootstrap=True,\n",
    "                class_weight=\"balanced_subsample\", \n",
    "                criterion='gini',\n",
    "                max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=4, min_samples_split=10,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                oob_score=False,\n",
    "                random_state=35,\n",
    "                verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7668b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(\"RF\", RandomForestClassifier(bootstrap=True,\n",
    "                class_weight=\"balanced_subsample\", \n",
    "                criterion='gini',\n",
    "                max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=4, min_samples_split=10,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                oob_score=False,\n",
    "                random_state=35,\n",
    "                verbose=0, warm_start=False), X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc79af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5776 4437]\n",
      " [2759 6241]]\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.676743     0.584473  0.625462      0.630608      0.633520\n",
      "recall         0.565554     0.693444  0.625462      0.629499      0.625462\n",
      "f1-score       0.616172     0.634312  0.625462      0.625242      0.624670\n",
      "support    10213.000000  9000.000000  0.625462  19213.000000  19213.000000\n",
      "Accuracy: 62.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.run_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01c1349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5776 4437]\n",
      " [2759 6241]]\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.676743     0.584473  0.625462      0.630608      0.633520\n",
      "recall         0.565554     0.693444  0.625462      0.629499      0.625462\n",
      "f1-score       0.616172     0.634312  0.625462      0.625242      0.624670\n",
      "support    10213.000000  9000.000000  0.625462  19213.000000  19213.000000\n",
      "Accuracy: 62.55%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>average precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.584473</td>\n",
       "      <td>0.693444</td>\n",
       "      <td>0.625462</td>\n",
       "      <td>0.634312</td>\n",
       "      <td>0.629499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  average precision  precision    recall  accuracy  f1 score  \\\n",
       "0         RF             0.5489   0.584473  0.693444  0.625462  0.634312   \n",
       "\n",
       "    roc_auc  \n",
       "0  0.629499  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNC\": KNeighborsClassifier(2),\n",
    "    \"GradBoost\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0),\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SGD\": SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "    \"LGBM\": LGBMClassifier(max_depth=10, num_leaves=246, n_estimators=380, min_data_in_leaf=20),\n",
    "    \"SVM\": LinearSVC(),\n",
    "    \"RF\": RandomForestClassifier(bootstrap=True,\n",
    "                class_weight=\"balanced_subsample\", \n",
    "                criterion='gini',\n",
    "                max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=4, min_samples_split=10,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                oob_score=False,\n",
    "                random_state=35,\n",
    "                verbose=0, warm_start=False),\n",
    "    \"MLP\": MLPClassifier(alpha=1, max_iter=1000)\n",
    "}\n",
    "\n",
    "        \n",
    "\n",
    "fitted_classifiers = {}\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    if name == \"RF\":\n",
    "        clf = Classifier(name, clf, X_train, y_train, X_test, y_test)\n",
    "        clf.run_classification()\n",
    "        clf.save_results()\n",
    "        results.append(clf.results)\n",
    "        fitted_classifiers[name] = clf\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(path + \"ML_classifiers_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb21287",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = \n",
    "feature_importances = pd.DataFrame([feats])\n",
    "feature_importances.T.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c071ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = models[\"RF\"]\n",
    "\n",
    "def get_model():\n",
    "    return RF\n",
    "\n",
    "def get_hyperparams():\n",
    "    return {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "search_parameters = {\n",
    "    \"cv\": 3,\n",
    "    \"verbose\": 0,\n",
    "    \"scoring\": 'f1_macro',\n",
    "    \"n_iter\": 20,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "bs = BayesSearchCV(get_model(), get_hyperparams(), **search_parameters)\n",
    "bs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs.best_params_)\n",
    "best = bs.best_estimator_\n",
    "best.fit(X_train, y_train)\n",
    "y_pred = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
